# GitHub ë ˆí¬ì§€í† ë¦¬ ì´ë¦„ ë° ì„¤ëª… ì¶”ì²œ

## ğŸ¯ ì¶”ì²œ ë ˆí¬ì§€í† ë¦¬ ì´ë¦„

### 1ìˆœìœ„: `kg-rag-benchmark` (í˜„ì¬ ì´ë¦„)
- âœ… ê°„ê²°í•˜ê³  ëª…í™•í•¨
- âœ… KG-RAG í”„ë ˆì„ì›Œí¬ë¥¼ ì§ì ‘ í‘œí˜„
- âœ… ë²¤ì¹˜ë§ˆí¬ ëª©ì ì´ ëª…í™•í•¨

### 2ìˆœìœ„: `biomedical-kg-rag`
- âœ… ë„ë©”ì¸(ë°”ì´ì˜¤ë©”ë””ì»¬) ëª…ì‹œ
- âœ… KG-RAG ê¸°ìˆ  ìŠ¤íƒ í‘œí˜„

### 3ìˆœìœ„: `synlethdb-qa-benchmark`
- âœ… ì‚¬ìš© ë°ì´í„°ì…‹(SynLethDB) ëª…ì‹œ
- âœ… QA ë²¤ì¹˜ë§ˆí¬ ëª©ì  ëª…í™•

## ğŸ“ ë ˆí¬ì§€í† ë¦¬ ì„¤ëª… (Description)

### ì§§ì€ ë²„ì „ (í•œ ì¤„)
```
A biomedical benchmark dataset generator using Knowledge Graphs and Retrieval-Augmented Generation (KG-RAG)
```

### ì¤‘ê°„ ë²„ì „ (2-3ì¤„)
```
KG-RAG: A framework for automatically generating biomedical question-answer pairs using Knowledge Graphs (SynLethDB) and Retrieval-Augmented Generation (PubMed). Generates 775 high-quality QA pairs for LLM evaluation.
```

### ìƒì„¸ ë²„ì „ (READMEìš©)
```
KG-RAG Benchmark: A Biomedical Benchmark for Large Language Models

Automatically generates high-quality biomedical question-answer pairs by combining:
- Knowledge Graphs (SynLethDB: 54K nodes, 2.2M edges)
- Retrieval-Augmented Generation (PubMed literature)
- Large Language Models (GPT-3.5/GPT-4)

Features:
- 4 question types: One-hop, Two-hop, Intersection, Attribute
- 775 validated QA pairs (from 1,000 generated)
- 95.98% average quality score
- Automated generation pipeline
```

## ğŸ·ï¸ ì¶”ì²œ Topics/Tags

```
biomedical-nlp
knowledge-graph
retrieval-augmented-generation
question-answering
benchmark-dataset
synlethdb
pubmed
llm-evaluation
biomedical-ai
rag
neo4j
```

## ğŸ“‹ README ìƒë‹¨ ì˜ˆì‹œ

```markdown
# KG-RAG Benchmark

> A Biomedical Benchmark for Large Language Models with Knowledge Graphs and Retrieval-Augmented Generation

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

Automatically generate high-quality biomedical question-answer pairs using Knowledge Graphs and RAG.

## ğŸš€ Quick Start

```bash
pip install -r requirements.txt
python src/qa_generator.py
```

## ğŸ“Š Dataset

- **Total**: 775 validated QA pairs
- **Question Types**: One-hop (50%), Two-hop (20%), Intersection (10%), Attribute (20%)
- **Quality Score**: 95.98% average
```

## ğŸ¨ ë ˆí¬ì§€í† ë¦¬ ì„¤ì • ì˜ˆì‹œ

### Description (ì§§ì€ ë²„ì „)
```
Biomedical QA benchmark generator using KG-RAG framework (SynLethDB + PubMed + LLM)
```

### Website (ë…¼ë¬¸ ë§í¬ê°€ ìˆë‹¤ë©´)
```
https://arxiv.org/abs/...
```

### Topics
```
biomedical-nlp, knowledge-graph, retrieval-augmented-generation, question-answering, benchmark-dataset, synlethdb, pubmed, llm-evaluation, biomedical-ai, rag, neo4j
```

## ğŸ’¡ ì¶”ê°€ ì œì•ˆ

### ë ˆí¬ì§€í† ë¦¬ ì´ë¦„ ì˜µì…˜ë“¤
1. `kg-rag-benchmark` â­ (ì¶”ì²œ)
2. `biomedical-kg-rag`
3. `kg-rag-biomedical-benchmark`
4. `synlethdb-qa-generator`
5. `biomedical-qa-kg-rag`

### ì„¤ëª… ì˜µì…˜ë“¤
1. **ê°„ê²°**: `Biomedical QA benchmark generator using KG-RAG (Knowledge Graph + RAG)`
2. **í‘œì¤€**: `A framework for automatically generating biomedical question-answer pairs using Knowledge Graphs and Retrieval-Augmented Generation`
3. **ìƒì„¸**: `KG-RAG Benchmark: Generate 775 high-quality biomedical QA pairs from SynLethDB knowledge graph and PubMed literature using LLMs`

